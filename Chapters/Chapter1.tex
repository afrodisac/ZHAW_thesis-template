% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%----------------------------------------------------------------------------------------
% CHAPTER 1
%----------------------------------------------------------------------------------------
\chapter{Introduction} % Main chapter title
\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1}

\subsection{Background}
The topic of flood modeling has become increasingly important due to the increased risk of urban flooding all over the world. Limitations of previous flood models are made increasingly apparent as the need for rapid modeling is required. Larger areas that were never at risk of flooding are now at risk. Severe, unexpected pluvial rainfall requires rapid modeling for prevension mechanisms. Unfortunately older methods just aren't fast enough. More recent CA models have allowed for faster modeling. Although these models are faster than traditional methods. They are still too slow, taking hours to model. This thesis proposes a machine learning approach to the problem of flood modeling. Deep learning has revolutionized many fields and many modeling tasks. The benefits of these models is how fast they perform computation. Often only requiring O(n) time complexity. Another feature of using deep learning approaches is that it can utilize the GPU (graphical processing unit) to further increase the speed of computation.

[Take2]
Climate change is rapidly becoming more and more of a problem with strange weather phenomenon becoming more common. Sea levels are rising and heavy rainfall in some regions results in more flooding in urban environments. The need for accurate and fast flood modeling is becoming critical in order to mitigate the effects of these weather phenomenon. Classical flood modeling is slow for large areas and requires a lot of compute power. Recently, Cellular automata have been used to accurately model flooding plains, however they are also relatively slow due to the amount of times you must iterate over the data, and they still make use of shallow water equations to do so. This is where we believe the novel use of NCA could be useful. They can make use of the gpu and require far less iterations to predict water depth and potentially velocity as well. NCA have an advantage over classical CNN as it has these residual blocks which allow for more classical simulation rather than just a classification.
The idea for applying machine learning methods to flood modeling isn't new. But previous approaches have had many problems, including not able to generalize to new catchment areas. 

[lets try to add the two together]
\subsection{Objective}
The objectives for this thesis are as follows:

\begin{enumerate}
	\item Normalize the data in such a way that data remains bound to physics \label{question1}
	\item Investigate different CNN model architectures and hyper parameters for predicting water depth. \label{qustion2} 
	\item Create a custom loss function that constrains the model to adhere to mass conservation. \label{question3}
	\item Can the model project arbitrarily into the future and predict multiple time steps ahead? \label{question4}
	\item Is the trained model computationally faster than the model proposed by \cite{Ghimire}? \label{question5}
\end{enumerate}